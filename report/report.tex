% !TEX TS-program = pdflatex
% !TEX encoding = UTF-8 Unicode

% This is a simple template for a LaTeX document using the "article" class.
% See "book", "report", "letter" for other types of document.

\documentclass[11pt]{article} % use larger type; default would be 10pt

\usepackage[utf8]{inputenc} % set input encoding (not needed with XeLaTeX)

%%% Examples of Article customizations
% These packages are optional, depending whether you want the features they provide.
% See the LaTeX Companion or other references for full information.

%%% PAGE DIMENSIONS
\usepackage{geometry} % to change the page dimensions
\geometry{a4paper} % or letterpaper (US) or a5paper or....
% \geometry{margin=2in} % for example, change the margins to 2 inches all round
% \geometry{landscape} % set up the page for landscape
%   read geometry.pdf for detailed page layout information

\usepackage{graphicx} % support the \includegraphics command and options

% \usepackage[parfill]{parskip} % Activate to begin paragraphs with an empty line rather than an indent

%%% PACKAGES
\usepackage{booktabs} % for much better looking tables
\usepackage{array} % for better arrays (eg matrices) in maths
\usepackage{paralist} % very flexible & customisable lists (eg. enumerate/itemize, etc.)
\usepackage{verbatim} % adds environment for commenting out blocks of text & for better verbatim
\usepackage{subfig} % make it possible to include more than one captioned figure/table in a single float
% These packages are all incorporated in the memoir class to one degree or another...

%%% HEADERS & FOOTERS
\usepackage{fancyhdr} % This should be set AFTER setting up the page geometry
\pagestyle{fancy} % options: empty , plain , fancy
\renewcommand{\headrulewidth}{0pt} % customise the layout...
\lhead{}\chead{}\rhead{}
\lfoot{}\cfoot{\thepage}\rfoot{}

%%% SECTION TITLE APPEARANCE
\usepackage{sectsty}
\allsectionsfont{\sffamily\mdseries\upshape} % (See the fntguide.pdf for font help)
% (This matches ConTeXt defaults)

%%% ToC (table of contents) APPEARANCE
\usepackage[nottoc,notlof,notlot]{tocbibind} % Put the bibliography in the ToC
\usepackage[titles,subfigure]{tocloft} % Alter the style of the Table of Contents
\renewcommand{\cftsecfont}{\rmfamily\mdseries\upshape}
\renewcommand{\cftsecpagefont}{\rmfamily\mdseries\upshape} % No bold!

 \setlength{\parindent}{0pt}

\usepackage{minted}
\usemintedstyle{borland}

\usepackage{amsmath, amssymb, amsthm}
\DeclareMathOperator{\EX}{\mathbb{E}}
\DeclareMathOperator{\Prob}{\mathbb{P}}
\DeclareMathOperator*{\argmax}{arg\,max}

\usepackage{xcolor}

\newtheorem*{assumption}{Assumption}
\newtheorem*{lemma}{Lemma}
\hyphenation{PriceBanditEnvironment}
%%% END Article customizations

%%% The "real" document content comes below...

\title{Advertising and Pricing}
\author{Gabriele Daglio, Federico Di Cesare, Jacopo Germano}
%\date{} % Activate to display a given date or no date (if empty),
         % otherwise the current date is printed 

\begin{document}
\maketitle

\section{The setting}

Advertising is used to attract users on an ecommerce website that sells only one type of item. Each day, a stochastic number of auctions $A$ is run by the ad publisher, each auction corresponding to a different user. The users are characterized by two binary features $F_1$ and $F_2$, which are independent and described by their probabilies $\theta_1$ and $\theta_2$ of assuming the value $True$ for a specific user.
Each user belongs to one of three classes, and the classes are determined by the combination of the two features. 
For each class $c \in C$ the following functions are modeled:
\begin{itemize}
\item A stochastic number of daily clicks of new users (i.e., that have never clicked before on the ads), represented by the discrete random variable $N_{c,b}$ such that $\EX[N_{c,b}] = n(c,b)$, where $b \in B$ is a bid value.
\item A conversion rate function providing the probability that a user will buy the item at a certain price,  $r(c,p)$, where $p \in P$ is the price. For each user of class $c$ that has clicked on the ad, a Bernoulli random variable $D_{c,p} \sim Bern(r(c,p))$ indicates whether the user bought the product ($D_{c,p}=1$) or not ($D_{c,p}=0$), such that $\EX[D_{c,p}]=r(c,p)$. We call this distribution $ClickConverted(c,p)$ and therefore $D_{c,p} \sim ClickConverted(c,p)$.
\item A probability distribution $FutureVisits(c)$ over the number of times a user of class $c$ will come back to the ecommerce website to buy that item by 30 days after the first purchase. In other words, when a user makes a purchase, they are somehow likely to make more purchases in the near future, and after that they will leave the website forever. For each user of class $c$, a discrete random variable $F_c \sim FutureVisits(c)$ indicates the number of times that the user came back, and for each class $c$ the function $f(c)$ is defined such that $\EX[F_c] = f(c)$
\item A probability distribution $CostPerClick(c,b)$. For each click, the random variable $C_{c,b}\sim CostPerClick(c,b)$ represents the amount that is paid to the ad publisher, such that $\EX[C_{c,b}] = k(c,b)$ and $\Prob(C_{c,b} \leq b) = 1$.
\end{itemize}

A margin function $m(p)$, where $p \in P$ is a price, is available to indicate how much profit is obtained if the an item is sold at the price $p$. 

\subsection {The binary features}
The features $F_1$ and $F_2$ are independent and are governed by the parameters $\theta_1$ and $\theta_2$. At the generation of the environment, the parameters $\theta_1$ and $\theta_2$ are randomly sampled, which represent the distribution of the feature values being for each user $u$: $\Pr(F_{1,u}=True)=\theta_1$ and $\Pr(F_{2,u}=True)=\theta_2$. Since the features are independent, for each combination we can compute the likelihood as follows:
\begin{align*}
\tilde{l}_{TT} &= \theta_1\theta_2\\
\tilde{l}_{TF} &= \theta_1(1-\theta_2)\\
\tilde{l}_{FT} &= (1-\theta_1)\theta_2\\
\tilde{l}_{FF} &= (1-\theta_1)(1-\theta_2)\\
\end{align*}

\subsection{The number of new daily clicks $N_{c,b}$}
First, the number of auctions $A$ run by the ad publisher is determined. The random variable $A$ is distributed as a Poisson $A\sim Poisson(\lambda_a)$, with the mean $\lambda_a$ being randomly chosen when the environment is generated.\\

The number $N_{c,b}$ of new daily clicks of users belonging to class $c$ is determined as follows: given the number of auctions $A$, the likelihood of each combination of the two binary features is used to sample from a Multinomial distribution:
\begin{align*}
(A_{TT},A_{TF},A_{FT},A_{FF}) \sim Multinomial(A, (\tilde{l}_{TT},\tilde{l}_{TF},\tilde{l}_{FT},\tilde{l}_{FF}))
\end{align*}
Where $A$ is the number of tries and  $ (\tilde{l}_{TT},\tilde{l}_{TF},\tilde{l}_{FT},\tilde{l}_{FF})$ is the vector of probabilities. This process basically assigns a combination of the features to each user involved in an auction of the ad publisher, according to the likelihood of each feature. The result, $(A_{TT},A_{TF},A_{FT},A_{FF})$, is the number of auctions run by the ad publisher for users of each combination. 

For each $comb \in \{TT,TF,FT,FF\}$ it holds $\EX[A_{comb}] = \lambda_a \tilde{l}_{comb}$ (Appendix \ref{sec.acombproof})
\newline
\newline
For each auction, a Bernoulli random variable is sampled to determine if the owner of the e-commerce has won the auction. We adopt the following assumption about the probability of winning an auction:
\begin{assumption}[Agnostic Publisher] The probability of winning an auction does not depend on the features that characterize the user, but only depends on the bid value $b$.
\end{assumption}
The meaning of the Agnostic Publisher assumption is that a change in the bid will change the number of users seeing the ad but will not change the percentage of users seeing it for each class. In other words, an increase in the auctions won will reflect in an increase in the number of clicks with the same proportion on all the classes.
\newline
\newline
We therefore define the function $v(b)$ representing the probability of winning one auction: it needs to be a monotonically increasing function of the bid ranging from $0$ to $1$. We chose a sigmoidal function for this purpose:
\begin{align*}
v(b)=\frac{1}{1+e^{-\overline z(b-\overline b)}}
\end{align*}
where $\overline z > 0$ and $\overline b > 0$ are randomly sampled when the environment is generated.
\newline
\newline
For simplicity we will assume that all the users that are displayed the ad will also click on it, therefore in our model the number of auctions won and the number of daily clicks coincide.
\newline
\newline
Finally, the number of clicks of users belonging to the combination of features $comb$, which is equivalent to the number of auctions won, is sampled from a Binomial:
\begin{align*}
\tilde{N}_{comb,b} \sim Binomial(A_{comb}, v(b))
\end{align*}
where $A_{comb}$ is the number of tries and $v(b)$ the probability of success of one try, and assuming that the function $combs(c)$ maps each class $c$ to the set of combinations of features that are covered by that class, we can compute
\begin{align*}
N_{c,b} = \sum_{comb \in combs(c)}{\tilde{N}_{comb,b}}
\end{align*}
Defining the likelihood $l_c$ of class $c$ as 
\begin{align*}
l_c = \sum_{comb \in combs(c)}{\tilde{l}_{comb}}
\end{align*}
we obtain the expression of the expected value of $N_{c,b}$ 
\begin{align*}
n(c,b) = \EX[N_{c,b}] =\lambda_al_{c}v(b)
\end{align*}
 (Appendix \ref{sec.ncbproof})

\subsection{The conversion rate $r(c,p)$}
For each class $c \in C$, the function $r_c(p)$ used to model the conversion rate of users belonging to that class must have the following properties:
\begin{itemize}
\item $r_c(0) \approx 1$: The user will be very likely to buy the product if it comes for free.
\item $\lim\limits_{p \to +\infty} r_c(p) = 0$: As the price goes to infinity, the probability that the user will buy it goes to zero.
\item $r_c(p)$ is monotonically decreasing with respect to p: an increase of the price will never increase the probability that the user will buy it.
\end{itemize}
The function $r(c,p)$ is then defined as: $r(c,p) := r_c(p)$.
Despite the fact that the functions $r_c(p)$ could be in principle defined in completely different ways, in our implementation we chose to use only (reflected, translated and horizontally scaled) sigmoidal functions:
\begin{align*}
r_c(p) = \frac{1}{1+e^{-z_c(P_c-p)}}
\end{align*}
Where $P_c$, the inflection point of the sigmoid, can be seen as the average reserve price of the users of the class and $z_c$ can be seen as the concentration of the reserve prices of the users around the average: if $z_c$ is small the reserve prices of the many users will be more distributed across the domain and the function will be more flat, while as $z_c$ grows the reserve prices of the many users will be more concentrated around the average and at the point $P_c$ there will be a rapid transition from "buy" to "don't buy".

\subsection{The future visits $F_c$}
We modeled the future visits with a Poisson random variable, such that $F_c \sim Poisson(f(c))$ and the mean $f(c)$ is constant and randomly sampled for each class when the environment is generated. We call the resulting distribution $FutureVisits(c)$, therefore $F_c \sim FutureVisits(c)$.

\subsection{The cost per click $C_{c,b}$}
The price paid for each click is in principle a stochastic function of the bid and of the user class. To limit the complexity of the model, we chose to model it such that the mean $k(c,b)$ is a percentage of the bid and the variable is always equal to its mean.

\begin{align*}
k(c,b) &= u_c\  b\\
\Prob(C_{c,b} = k(c,b)) &= 1
\end{align*}
With the percentage $0 < u_c < 1$ being randomly sampled for each class when the environment is generated.
We call this distribution $CostPerClick(c,b)$, therefore $C_{c,b}\sim CostPerClick(c,b)$.

\subsection{Margin function $m(p)$}
At the generation of the environment, the base price $p_{base}$ of the item is randomly sampled. This is the price that the seller has paid to produce the item. We assume that the tax domicile of the e-commerce is located in the Cayman Islands, therefore the owner pays no taxes whatsoever, and the margin function $m(p)$ is defined as follows:
\begin{align*}
m(p)=p-p_{base}
\end{align*}
And it represents the profit that the seller makes by selling one item at price $p$.

\clearpage
\section{Step 1}
The goal is to maximize the expected profit over a single day, where the future visits of a user are considered to contribute in expected value to the profit of the day of the first visit.
\newline
\newline
For each class $c$, we consider:
\begin{itemize}
\item The random variable $N_{c,b}$ representing the number of new clicks of users of class $c$.
\item The sequence $(C_{c,b,i})_{i=1,...,N_{c,b}}$ of random variables representing the cost paid for each click $i$, such that $C_{c,b,i}\sim CostPerClick(c,b)$
\item The sequence $(D_{c,p,i})_{i=1,...,N_{c,b}}$ of random variables representing whether user $i$ of class $c$ purchased the item, such that $D_{c,p,i}\sim ClickConverted(c,p)$
\item The sequence $(F_{c,i})_{i=1,...,N_{c,b}}$ of random variables representing the number of future visits of the user $i$ of class $c$, such that $F_{c,i}\sim FutureVisits(c)$
\end{itemize}
With these variables we can express the expected profit as follows:
\begin{align*}
ExpectedProfit(p,b) = \EX\left[\sum_{c \in C}{\sum_{i =1}^{N_{c,b}}{\bigg( D_{c,p,i}(1+F_{c,i})m(p)-C_{c,b,i}\bigg)}}\right]
\end{align*}
And therefore formulate the optimization problem as follows:
\begin{align*}
\argmax_{p,b}{\ ExpectedProfit(p,b)}
\end{align*}

With some manipulations using the properties of the expected value (Appendix \ref{sec.DerExpProf}), the expected profit can be expressed as follows:

\begin{align*}
ExpectedProfit(p,b)=\sum_{c \in C}{n(c,b)\Big(m(p)r(c,p)(1+f(c))-k(c,b)\Big)}
\end{align*}

Obtaining the following formulation of the optimization problem which depends only on the means of the distributions:

\begin{align*}
\argmax_{p,b}{\ \sum_{c \in C}{n(c,b)\Big(m(p)r(c,p)(1+f(c))-k(c,b)\Big)}}
\end{align*}

Under the Agnostic Publisher assumption, the following interesting result holds:

\begin{lemma}[Bid Independent Price Hierarchy]
If $ExpectedProfit(p_1,\overline b) \ge ExpectedProfit(p_2,\overline b)$ for some bid value $\overline b$,  then $ExpectedProfit(p_1, b') \ge ExpectedProfit(p_2, b')$  for every possible bid value $b'$.
\end{lemma}
\begin{proof}
see Appendix \ref{sec.BIPHLProof}.
\end{proof}

As a consequence of this result, we developed an algorithm that:
\begin{enumerate}
\item Finds the optimal price $p^*\in P$ that maximizes $ExpectedProfit(p,\overline b)$ for a fixed bid value $\overline b$ (We take the median of the set of possible values). The time complexity of this step is $O(|P|)$
\item Finds the optimal bid value $b^* \in B$ that maximizes $ExpectedProfit(p^*, b)$, using the optimal price $p^*$ found at step 1, which is still optimal thanks to the above lemma. The time complexity of this step is $O(|B|)$
\item Returns the solution $(p^*, b^*)$.
\end{enumerate}
And computes the optimal solution with a time complexity of $O(|P|+|B|)$.\\

The implementation is as follows:\\
We first define the function \textit{ExpectedProfit(p,b)}:
\inputminted{python}{code/step1_expected_profit.py}

Where the function \textit{simple\_class\_profit(...)} is defined as:
\inputminted{python}{code/step1_simple_class_profit.py}
\begin{samepage}
The algorithm is as follows:
\inputminted{python}{code/step1.py}
\end{samepage}
The methods \textit{optimal\_price\_for\_bid(b)} and \textit{optimal\_bid\_for\_price(p)} are implemented as follows:
\inputminted{python}{code/step1_support.py}

\clearpage
\section{Step 2}
We can model the online version of the above optimization problem as follows: each day corresponds to a round, and the learning horizon is $H=365$ rounds. Before each round the learner specifies the price $p$ and the bid $b$ that will be used, while at the end of the round $j$ the learner will receive the following information:
\begin{itemize}
\item The number of auctions $a_j$ that were run by the ad publisher during that round
\item The number of new clicks  $n_j$ received during that round
\item The number of purchases of new users $s_j$ that happened during that round 
\item The total cost that was paid to the ad publisher $c_j$
\item The total number $f_{j-30}$ of subsequent purchases done by users that did the first purchase on round $j-30$. (If $j < 30$, this information will be omitted).
\end{itemize}
It must be noticed that there is a partially delayed feedback: in fact, the future visits of the users are defined as the number of subsequent purchases in the next 30 days and the learner will need to wait as many rounds to know the number of future visits that was realized, while they will be immediately aware of the realization of the other values.\\

The learner's goal should be to estimate the expected profit of all the pricing/bidding strategies $(p,b)$, in order to employ the most profitable one. At round $i>30+|P|$, this estimation can be obtained by computing the expected value according to the formula defined in step 1, estimating:
\begin{itemize}
\item The average number of daily auctions $\overline a$ as the sample mean of the previously observed $a_js$: \[\overline a_i=\frac{1}{i}\sum_{j=0}^{i-1}{a_j}\]
\item For each bid value $b$, the average number of new clicks  $\overline{n_b}$ as the mean of the observed $n_j$, considering only the rounds where the bid $b$ was employed: \[\overline{n_b}_i=\frac{1}{|\{j: b_j=b\}|}\sum_{j\in\{j: b_j=b\}}{n_j}\]
\item For each price $p$, the conversion rate $\overline{r_p}$ as the ratio between the number of purchases and that of new clicks, considering only the rounds where the price $p$ was employed: \[\overline{r_p}_i=\frac{\sum_{j\in\{j:p_j=p\}}{s_j}}{\sum_{j\in\{j:p_j=p\}}{n_j}}\]
\item For each bid value $b$, the average cost per click $\overline{c_b}$ that was paid to the ad publisher $c_j$ as the ratio between the total cost paid and the total number of clicks,  considering only the rounds where the bid $b$ was employed:  \[\overline{c_b}_i=\frac{\sum_{j\in\{j:b_j=b\}}{c_j}}{\sum_{j\in\{j:b_j=b\}}{n_j}}\]
\item For each price $p$, the average number $\overline{f_p}$ of subsequent purchases done by users as the ratio between the total number of subsequent purchases of users of round $j$ and the number of purchases of round $j$, considering only the rounds where the price $p$ was employed and for which the delayed feedback has been received: \[\overline{f_p}_i=\frac{\sum_{j\in\{j:p_j=p, j\le i-30\}}{f_j}}{\sum_{j\in\{j:p_j=p, j\le i-30\}}{s_j}}\]
\item For each bid value $b$, the probability $\overline{w_b}$ of winning the auction as the ratio between the number of new clicks and the number of auctions (recall that we are assuming that every user which is displayed the ad will also click on it), considering only the rounds where the bid $b$ was employed:  \[\overline{w_b}_i=\frac{\sum_{j\in\{j:b_j=b\}}{n_j}}{\sum_{j\in\{j:b_j=b\}}{a_j}}\]
\end{itemize}
After all these estimates have been computed, the learner can make a projecton of the expected profit $\widehat{exp(p,b)}_i$ of the strategy $(p,b)$ as: \[\widehat{exp(p,b)}_i=\overline{a}_i\overline{w_b}_i\bigg(m(p)\overline{r_p}_i(1+\overline{f_p}_i) -\overline{c_b} \bigg) \]
The estimation can be done efficiently because none of the quantities to estimate depends on both $p$ and $b$. {\color{red}It may be non trivial to notice that the estimate of $\overline{f_p}$ can be computed summing the sample that come from rounds where different bids were used}. Using the estimation the learner will choose $(p_i,b_i)$ and the learning process will move one round forward.\\
Since the learner is optimizing on $p$ and $b$, they should not use the expected profit but rather an optimistic estimate of the expected profit, which can be obtained by applying to the conversion rate $\overline{r_p}_i$ and to the winning probability $\overline{w_b}_i$ optimistic exploration techniques such as upper confidence bounds or Thompson sampling and using those values instead of the sample means.\\

\textbf{Note:} \textit{The number of rounds $30+P$ after which the learner begins to compute the estimates is to ensure that all the prices have received at least one delayed feedback in the case the learner performs round robins for the first $P$ rounds, which corresponds to our implementation.}


\clearpage
\section{Step 3}
In order to learn in an online fashion the best pricing strategy for a fixed bid value, we have implemented a python object called \textit{OptimalPriceLearner} and one called\\ \textit{PriceBanditEnvironment}, which has internally an instance of the \textit{Environment} object. 

Upon the creation of an instance of a \textit{PriceBanditEnvironment}, the underlying\\ \textit{Environment}, the set of possible prices and the fixed bid value must be supplied as arguments. The bandit environment hides the actual prices $P$ from the learner, and instead it shows a bandit-like set of arms numbered from $0$ to $|P|-1$.\\

The \textit{PriceBanditEnvironment} exposes the method \mbox{\textit{pull\_arm\_not\_discriminating(arm: int)}}, which returns the aggregated data:\\
\mbox{\textit{new\_clicks, purchases, tot\_cost\_per\_clicks, (past\_arm, past\_future\_visits)}}.\\

These data implement the round output specified at step 2, with the exception of \textit{past\_arm} which is just a reminder of the arm that was chosen at the round in which the delayed feedback started. 

The learning loop is as follows:
\inputminted{python}{code/step3_learning_loop.py}
It is clear that the learner chooses to pull the arm that has the highest projected profit, which is, for each arm, the profit computed with an optimistic estimate of the conversion rate associated to the arm itself.

Let's see how the learner computes the projected profits:
\inputminted{python}{code/step3_projected_profits.py}
Note that since the conversion rates are numpy arrays, the result is a numpy array with one entry for each arm.

The estimators $\overline{f_p}$ of the average future visits associated with a price and $\overline{n}$ of the average number of new clicks are computed as follows:
\inputminted{python}{code/step3_estimates.py}
It remains to determine how to make an optimistic estimate of the conversion rates: this is left to implement to the subclasses, as in the class \textit{OptimalPriceLearner} the methods are defined as abtract, with the python convention.
\inputminted{python}{code/step3_conversion_rates.py}
We created two subclasses, one that employs a UCB approach and one that employs a Thompson sampling approach.\\

\begin{samepage}
\subsection{The class \textit{UCBOptimalPriceLearner}}
We implemented the UCB approach by subclassing  \textit{OptimalPriceLearner} and overriding the following methods:
\inputminted{python}{code/step3_ucb.py}
\end{samepage}
The average of the conversion rate is estimated, for each arm, as $\mu_a=\frac{purchases_a}{clicks_a}$ and the confidence bound radius is computed with the same formula of the UCB1 algorithm for the Bernoulli stochastic bandit environments: $r_a=\sqrt{\frac{2log(t)}{clicks_a}}$.
Then, the upper bound $u_a = \mu_a+r_a$ is used as optimistic conversion rate of each arm $a$ to estimate the expected profit in the parent class learning loop.\\

It should be noticed that since each click is treated as a separate try of a Bernoulli random variable, the updates to the average and to the confidence bounds happen in batches, that is after one round we do not see the realization of one additional try but rather that of $new\_clicks$ additional tries of the same arm.\\

\begin{samepage}
\subsection{The class \textit{TSOptimalPriceLearner}}
The Thompson sampling learner samples keeps a Beta distribution for each arm and samples the optimistic (or rather, explorative) conversion rate that will be used for that arm:
\inputminted{python}{code/step3_ts_cr.py}
\end{samepage}
The parent's \textit{pull\_from\_env(arm)} method is overridden to update the betas whenever new samples are obtained.
\inputminted{python}{code/step3_ts_betas.py}
It should be noticed that since each click is treated as a separate try of a Bernoulli random variable, the updates to the parameters $\alpha$ and $\beta$ happen in batches, that is after one round we do not see the realization of one additional try but rather that of $new\_clicks$ additional tries of the same arm.

\clearpage
\subsection{Experiment 1}
\makebox[\linewidth]{\includegraphics[scale=0.4]{figures/step3/env0.png}}
\makebox[\linewidth]{\includegraphics[scale=0.7] {figures/step3/plot0.png}}

\clearpage
\verbatiminput{figures/step3/output0.txt}

\clearpage
\subsection{Experiment 2}
\makebox[\linewidth]{\includegraphics[scale=0.4]{figures/step3/env1.png}}
\makebox[\linewidth]{\includegraphics[scale=0.7] {figures/step3/plot1.png}}

\clearpage
\verbatiminput{figures/step3/output1.txt}

\clearpage
\section{Step 4}
In order to perform context generation, the information that the learner receives at each round is divided by combination of features: the method \textit{pull\_arm\_discriminating(arm\_strategy)} accepts a strategy that defines one arm (which means one price) for each combination of features, and returns:
\begin{itemize}
\item $n_{TT},n_{TF},n_{FT},n_{FF}$ The new clicks of users of each combination of features.
\item $s_{TT}, s_{TF},s_{FT},s_{FF}$ The purchases of users of each combination of features.
\item $c_{TT},c_{TF},c_{FT},c_{FF}$ The total cost per click paid due to clicks of users of each combination of features.
\item $f_{TT},f_{TF},f_{FT},f_{FF}$ The total future purchases of users of each combination of features which visited the website for the first time $30$ rounds ago.
\end{itemize}
Receiving the data in this way, the learner can try any possible strategy and observe the disaggregate result without having access to the underlying class structure.
The learner, defined by the class \textit{OptimalPriceDiscriminatingLearner}, keeps track of the context generation thanks to the attribute \textit{context structure}, which is a list of objects of the class \textit{Context}. A \textit{Context} object contains a subset of the combinations of features and the learner initially starts with one context containing all the possible combinations. The estimation of the parameters and of the expected value is performed by each $Context$ with the same logic as the non-discriminating learner, by working on the aggregate data aggregated only on its subset of features.

The learning loop is as follows:
\inputminted{python}{code/step4_learning_loop.py}

\begin{samepage}
The strategy selection must choose one arm for each combination of features: in order to do so, it queries the contexts and each context specifies the next arm for its combinatioins. Let us remind that the contexts always form a partition of the full feature space.
\inputminted{python}{code/step4_choose_next_strategy.py}
\end{samepage}
Let us skip for the moment the code of the method \textit{choose\_next\_strategy\_explorative()}, which is a marginal modification that we have introduced and which we will present later.\\
One can notice that each context has the method \textit{choose\_next\_arm(...)}. In this method, each context computes the expected profit with an optimistic / explorative estimate of the conversion rate and returns the arm with the highest projection of profit, estimating all the parameters with aggregated data relative only to the covered set of combinations of features.

\inputminted{python}{code/step4_context_next_arm.py}
We don't report the code of the method \textit{compute\_projected\_profit()} since it is identical to the analogous method of the class \textit{OptimalPriceLearner}. Also in this case, the method \textit{compute\_projection\_conversion\_rate()} is defined as abstract to allow for different implementations of explorative strategies.\\

The second core method is \textit{update\_contexts()}:
\inputminted{python}{code/step4_update_contexts.py}
For each context, among all the splits that are convenient, it takes the one that is convenient by the largest amount.\\

Let's see how the convenient splits are computed:

\inputminted{python}{code/step4_convenient_split.py}

The condition of convenience is that the lower bound of the expected profit after the split is higher that the current lower bound.\\

For completeness we report also the implementation of the computation of the possible splits:
\inputminted{python}{code/step4_possible_split.py}
\begin{samepage}
\subsection{The class \textit{UCBOptimalPriceDiscriminatingLearner}}
Since the logic of the choice of explorative estimates of the conversion rates is performed by the contexts, this class is just a wrapper to instruct the parent class to instantiate \textit{UCBContext} objects when contexts are created.

\inputminted{python}{code/step4_ucb_disc.py}
Here we can see how the \textit{UCBContext} overrides  \textit{compute\_projection\_conversion\_rate()}:
\inputminted{python}{code/step4_ucbcontext_projection.py}
The confidence bound formula is the same as in \textit{UCBOptimalPriceLearner}.
\end{samepage}
\\

\begin{samepage}
\subsection{The class \textit{TSOptimalPriceDiscriminatingLearner}}
We can see the same pattern of the previous class:
\inputminted{python}{code/step4_ts_disc.py}

Here we can see how the \textit{TSContext} overrides  \textit{compute\_projection\_conversion\_rate()}:
\inputminted{python}{code/step4_tscontext_projection.py}
As in Step 3, the Thompson sampling approach samples from the Beta distributions and uses them as the projection values.
\end{samepage}
\\

\begin{samepage}
\subsection{\textit{choose\_next\_strategy\_explorative()}}
We added the explorative rounds after the following empiric observation: the splits that could not be detected after the initial round robin are never detected if their optimal arm is very sub-optimal for the current context, since the lower confidence bound will never get tighter (it will almost never be pulled). Therefore we added the \textit{explorative rounds}, rounds in which the contexts which could be split do not pull the best arm according to their strategy but rather pulll the arms in a round-robin fashion, to allow the confidence bounds of the currently sub-optimal arms to get tighter. We ensure that the number of explorative rounds remains logarithmic in the following way: after the $i_{th}$ explorative round robin has been completed, $2^i$ normal rounds must be completed before running the $i+1_{th}$ explorative round robin. From the regret plots below, one can clearly see the explorative rounds as the regret makes a step.

\inputminted{python}{code/step4_choose_next_strategy_explorative.py}
\end{samepage}

\clearpage
\subsection{Experiment 1}
\makebox[\linewidth]{\includegraphics[scale=0.4]{figures/step4/env0.png}}
\makebox[\linewidth]{\includegraphics[scale=0.7] {figures/step4/plot0.png}}

\clearpage

{\footnotesize\verbatiminput{figures/step4/output0.txt}}

\clearpage
\subsection{Experiment 2}
\makebox[\linewidth]{\includegraphics[scale=0.4]{figures/step4/env1.png}}
\makebox[\linewidth]{\includegraphics[scale=0.7] {figures/step4/plot1.png}}

\clearpage

{\footnotesize\verbatiminput{figures/step4/output1.txt}}

\clearpage
\subsection{Experiment 3}
\makebox[\linewidth]{\includegraphics[scale=0.4]{figures/step4/env2.png}}
\makebox[\linewidth]{\includegraphics[scale=0.7] {figures/step4/plot2.png}}

\clearpage

{\footnotesize\verbatiminput{figures/step4/output2.txt}}

\clearpage
\section{Step 5}
In order to learn online the best bid for a fixed price, we implement a simmetric approach with respect to Step 3, with which it has  many similarities. We defined the class \textit{BidBanditEnvironment}, which has internally an instance of \textit{Environment}. Upon the creation of an instance of a \textit{BidBanditEnvironment}, the underlying \textit{Environment}, the set of possible bids and the fixed price value must be supplied as arguments. The bandit environment hides the actual bids $B$ from the learner, and instead it shows a bandit-like set of arms numbered from $0$ to $|B|-1$.\\

The \textit{BidBanditEnvironment} exposes the method \textit{pull\_arm\_not\_discriminating(arm: int)} which returns to the aggregated data:\\
\textit{auctions, new\_clicks, purchases, tot\_cost\_per\_clicks, (past\_arm, past\_future\_visits)}.\\
We can notice that the number of auctions run by the advertiser is also communicated to the learner, differently from the \textit{PriceBanditEnvironment} of Step 3.\\

The \textit{OptimalBidLearner} is also similar to the learner of Step 3, it is evident from the core learning loop:
\inputminted{python}{code/step5_learning_loop.py}
The arm selection logic is, as always, to pull the arm with the highest expected profit, computed with an optimistic / explorative estimate of the parameter (in this case, the probablity of winning an auction with a certain bid value). However, here we notice a difference: a safety constraint is introduced to prevent the learner from playing arms that would yield a negative profit with a probability greater or equal to a certain threshold. We call this threshold the \textit{security} parameter, which is set by default to $0.2$.\\

\begin{samepage}
The set of safe arms is computed as follows:
\inputminted{python}{code/step5_safety_constraint.py}
\end{samepage}

A safe arm is defined as an arm which revenue won't be negative with a certain probability. To compute the set of safe
arms we perform normal regression with the data of our random variable (the new clicks) and assuming we not to sell the
product below cost we can take the 20th percentile of the distribution and compute the expected profit with that value.
This way we are sure that no more than the 20\% of the times we will have a lower profit. The security parameters
regulates how much "safe" we want to be.

The computation of the projection of profit for each arm is as follows:

\inputminted{python}{code/step5_projected_profit.py}

\begin{samepage}
The estimated quantities are computed in the following way:
\inputminted{python}{code/step5_estimated_quantities.py}
\end{samepage}
While the method \textit{compute\_projection\_auction\_winning\_probability\_per\_arm()} is defined as abstract to allow for the implementation of different explorative strategies.

\subsection{The class \textit{UCBOptimalBidLearner}}
We have chosen the UCB approach to continue the assignment, the upper confidence bounds for the probability of winning an auction with a given bid value are computed in the following way:

\inputminted{python}{code/step5_ucb_win_prob.py}

The bound is the standard upper confidence bound used by UCB1 for stochastic Bernoulli bandits, where each auction is considered one try and the click of the user (which under our assumption is equivalent to winning the auction) is the success.

\clearpage
\subsection{Experiment 1}
\makebox[\linewidth]{\includegraphics[scale=0.4]{figures/step5/env0.png}}
\makebox[\linewidth]{\includegraphics[scale=0.7] {figures/step5/plot0.png}}

\clearpage

{\footnotesize\verbatiminput{figures/step5/output0.txt}}

\clearpage
\subsection{Experiment 2}
\makebox[\linewidth]{\includegraphics[scale=0.4]{figures/step5/env1.png}}
\makebox[\linewidth]{\includegraphics[scale=0.7] {figures/step5/plot1.png}}

\clearpage

{\footnotesize\verbatiminput{figures/step5/output1.txt}}



\clearpage
\section{Step 6}
In this step we have to learn in online fashion both the price and the bid, while not discriminating among the customer
classes. In other words we will work only with aggregate data and we will provide a single optimal tuple of arms.
The rationale behind our approach is the following: we still have two random variables, the conversion rate (pricing
problem) and the probability of winning an auction (bidding problem). All the other quantities involved in the problem
depend only on one of the two random variables. We have to store our data in a matrix, with the two axis being the prices
and the bids, but since a quantity will depend only on one single axis, during the learning we can project this quantity
on the other axis and thus exploit the functions we wrote before for the disjointed problems.

The environment is an instance of \textit{JointBanditEnvironment} which is pretty much the same as \textit{PriceBanditEnvironment}
and \textit{BidBanditEnvironment}, but the method \\ \textit{pull\_arm\_not\_discriminating} accepts both a price arm and a
bid arm.
As for the delayed feedback, being a joint problem environment, this class will return the future visits with a tuple of
arms, not with a single arm as before.

The learning loop is the very same as the previous steps so there is no point in reporting it here again, what is
interesting is the routine for choosing and arm. Here we exploit the results from Step 1, where we stated that the optimal
price is constant for all the bids. Indeed to choose the next tuple of arms we firstly compute the price arm we want to
pull with a fixed bid, then given that price arm, we compute the bid arm we want to pull.
\inputminted{python}{code/step6_choose_arm.py}
Note that there still is the safety constraint introduced at step 5.

Since the choice of the arms is divided in two steps, we have the two functions to select the most promising arm, namely
\textit{compute\_projected\_profits\_fixed\_bid} and \textit{compute\_projected\_profits\_fixed\_price} which are reported below.
\inputminted{python}{code/step6_expected_price_fixed_bid.py}
\inputminted{python}{code/step6_expected_price_fixed_price.py}

In the reported code we can notice some interesting functions that exploit the technique of axis projection. Here are the
mentioned functions.
\inputminted{python}{code/step6_axis_projected_quantities.py}

The random variables of this step, namely the conversion rates and the winning probability for an auction, are computed
in the same way we did in the previous steps.
\inputminted{python}{code/step6_random_variables_computation.py}

Note the abstract methods that will allow us to implement specific learners to tackle the problem.

\subsection{The class \textit{UCBOptimalJointLearner}}
This class implements the abstract methods described before, in order to provide an UCB learner for the given scenario.
The most interesting methods are those to compute the radii for the UCB upper bound of our random variables.
\inputminted{python}{code/step6_computation_radii.py}

We need also to compute the average winning probability for each bid. Note that also here we project the data by summing
over the price arms.
\inputminted{python}{code/step6_computation_winning_probability.py}


\clearpage
\subsection{Experiment 1}
\makebox[\linewidth]{\includegraphics[scale=0.4]{figures/step6/env0.png}}
\makebox[\linewidth]{\includegraphics[scale=0.7] {figures/step6/plot0.png}}

\clearpage
{\footnotesize\verbatiminput{figures/step6/output0.txt}}

\clearpage
\subsection{Experiment 2}
\makebox[\linewidth]{\includegraphics[scale=0.4]{figures/step6/env1.png}}
\makebox[\linewidth]{\includegraphics[scale=0.7] {figures/step6/plot1.png}}

\clearpage
{\footnotesize\verbatiminput{figures/step6/output1.txt}}

\clearpage
\subsection{Experiment 3}
\makebox[\linewidth]{\includegraphics[scale=0.4]{figures/step6/env2.png}}
\makebox[\linewidth]{\includegraphics[scale=0.7] {figures/step6/plot2.png}}

\clearpage
{\footnotesize\verbatiminput{figures/step6/output2.txt}}

\clearpage
\section{Step 7}
{\color{red}da scrivere}


\clearpage
\appendix

\section{Expected Value of $A_{comb}$}\label{sec.acombproof}
For each $comb \in \{TT,TF,FT,FF\}$ it holds $\EX[A_{comb}] = \lambda_a \tilde{l}_{comb}$
\newline
\newline
Consider the daily number of auctions A.
\begin{align*}
\EX\left[A_{comb}\right] = \EX\left[\EX\left[A_{comb}|A\right]\right]
\end{align*}
Since $A_{comb}$ is sampled from a multinomial with $A$ tries and with associated probability $\tilde{l}_{comb}$, it holds
\begin{align*}
\EX\left[A_{comb}\right] &= \EX\left[A\tilde{l}_{comb}\right]\\
&= \EX\left[A\right]\tilde{l}_{comb}\\
&= \lambda_a\tilde{l}_{comb}
\end{align*}

\section{Expected Value of $N_{c,b}$}\label{sec.ncbproof}
Since $\tilde{N}_{comb,b} \sim Binomial(A_{comb}, v(b))$, it holds
\begin{align*}
\EX\left[\tilde{N}_{comb,b}\right] &= \EX\left[\EX\left[\tilde{N}_{comb,b}| A_{comb}\right]\right]\\
 &= \EX\left[A_{comb}v(b)\right]\\
 &= \EX\left[A_{comb}\right]v(b)\\
&= \lambda_a\tilde{l}_{comb}v(b)
\end{align*}
therefore
\begin{align*}
\EX\left[N_{c,b}\right] &= \sum_{comb \in combs(c)}{\EX\left[\tilde{N}_{comb,b}\right]}\\
&= \sum_{comb \in combs(c)}{\lambda_a\tilde{l}_{comb}v(b)}\\
&= \lambda_av(b)\sum_{comb \in combs(c)}{\tilde{l}_{comb}}
\end{align*}
And by definition of the likelihood $l_c$ of a class:
\begin{align*}
\EX\left[N_{c,b}\right]&= \lambda_av(b)l_c
\end{align*}

\clearpage
\section{Derivation of ExpectedProfit}\label{sec.DerExpProf}
\begin{align*}
ExpectedProfit(p,b) 
&= \EX\left[\sum_{c \in C}{\sum_{i =1}^{N_{c,b}}{\bigg( D_{c,p,i}(1+F_{c,i})m(p)-C_{c,b,i}\bigg)}}\right]\\
&= \EX_{n_{c,b}}\left[\EX\left[\sum_{c \in C}{\sum_{i =1}^{N_{c,b}}{\bigg( D_{c,p,i}(1+F_{c,i})m(p)-C_{c,b,i}\bigg)}}\bigg|N_{c,b}=n_{c,b}\right]\right]\\
&= \EX_{n_{c,b}}\left[\sum_{c \in C}{\sum_{i =1}^{n_{c,b}}{\bigg(\EX\bigg[D_{c,p,i}(1+F_{c,i})m(p)-C_{c,b,i}\bigg|N_{c,b}=n_{c,b}\bigg]\bigg)}}\right]\\
&= \EX_{n_{c,b}}\left[\sum_{c \in C}{\sum_{i =1}^{n_{c,b}}{\bigg(\EX\bigg[D_{c,p,i}(1+F_{c,i})m(p)\bigg|N_{c,b}=n_{c,b}\bigg]-k(c,b)\bigg)}}\right]\\
&= \EX_{n_{c,b}}\left[\sum_{c \in C}{\sum_{i =1}^{n_{c,b}}{\bigg(r(c,p)(1+f(c))m(p)-k(c,b)\bigg)}}\right]\\
&= \EX_{n_{c,b}}\left[\sum_{c \in C}{n_{c,b}\bigg(r(c,p)(1+f(c))m(p)-k(c,b)\bigg)}\right]\\
&=\sum_{c \in C}{ \EX_{n_{c,b}}\left[n_{c,b}\bigg(r(c,p)(1+f(c))m(p)-k(c,b)\bigg)\right]}\\
&=\sum_{c \in C}{ \EX_{n_{c,b}}\left[n_{c,b}\right]\bigg(r(c,p)(1+f(c))m(p)-k(c,b)\bigg)}\\
&=\sum_{c \in C}{ \EX\left[N_{c,b}\right]\bigg(r(c,p)(1+f(c))m(p)-k(c,b)\bigg)}\\
&=\sum_{c \in C}{ n(c,b)\bigg(r(c,p)(1+f(c))m(p)-k(c,b)\bigg)}\\
\end{align*}

\clearpage
\section{Proof of the Bid Independent Price Hierarchy lemma}\label{sec.BIPHLProof}
\begin{align*}
ExpectedProfit(p,b)&=\sum_{c \in C}{ n(c,b)\bigg(r(c,p)(1+f(c))m(p)-k(c,b)\bigg)}\\
&=\lambda_av(b)\sum_{c \in C}{l_{c}\Big(r(c,p)(1+f(c))m(p)-k(c,b)\Big)}
\end{align*}
\begin{align*}
\lambda_av(b)\sum_{c \in C}{l_{c}\Big(r(c,p_1)(1+f(c))m(p_1)-k(c,b)\Big)} &\ge \lambda_av(b)\sum_{c \in C}{l_{c}\Big(r(c,p_2)(1+f(c))m(p_2)-k(c,b)\Big)}
\end{align*}
Since $\lambda_a>0$ and $v(b)>0$:
\begin{align*}
\sum_{c \in C}{l_{c}\Big(r(c,p_1)(1+f(c))m(p_1)-k(c,b)\Big)} &\ge \sum_{c \in C}{l_{c}\Big(r(c,p_2)(1+f(c))m(p_2)-k(c,b)\Big)}\\
\sum_{c \in C}{l_{c}r(c,p_1)(1+f(c))m(p_1)}-\sum_{c \in C}{l_{c}k(c,b)} &\ge \sum_{c \in C}{l_{c}r(c,p_2)(1+f(c))m(p_2)}-\sum_{c \in C}{l_{c}k(c,b)}
\end{align*}
Since the term $\sum_{c \in C}{l_{c}k(c,b)}$ appears on both sides:
\begin{align*}
\sum_{c \in C}{l_{c}r(c,p_1)(1+f(c))m(p_1)} &\ge \sum_{c \in C}{l_{c}r(c,p_2)(1+f(c))m(p_2)}
\end{align*}
Since all the steps can be reversed with an arbitrary bid $b'$, the relation holds for every possible value of the bid.
\end{document}
